<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>DOCSSS</title>
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.5.2/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/simple-datatables@7.1.2/dist/style.min.css" rel="stylesheet" />
    <link href="styles.css" rel="stylesheet" />
    <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
    <style>
        .result-box {
            border: 1px solid #ccc;
            padding: 10px;
            margin-top: 20px;
            min-height: 100px;
            background-color: #f9f9f9;
        }

        body {
            padding-top: 20px;
        }

        .loading-spinner {
            display: none;
            width: 3rem;
            height: 3rem;
        }

        #imagePreview {
            margin-top: 20px;
            max-height: 200px;
        }
    </style>
</head>

<body class="sb-nav-fixed">
    <nav class="sb-topnav navbar navbar-expand navbar-dark bg-dark">
        <!-- Navbar Brand-->
        <a class="navbar-brand ps-3" href="/">Extrait d'Entit√©s Nomm√©es (NER)</a>
        <!-- Sidebar Toggle-->
        <button class="btn btn-link btn-sm order-1 order-lg-0 me-4 me-lg-0" id="sidebarToggle" href="#!"><i
                class="fas fa-bars"></i></button>
        <!-- Navbar Search-->
        <div class="d-none d-md-inline-block ms-auto me-0 me-md-3 my-2 my-md-0">
            <a class="btn btn-primary" href="https://github.com/" role="button" style><i class="fab fa-github"></i>
                Repos GitHub</a>
        </div>

        <!-- Navbar-->
        <ul class="navbar-nav ms-auto ms-md-0 me-3 me-lg-4">
        </ul>
    </nav>
    <div id="layoutSidenav">
        <div id="layoutSidenav_nav">
            <nav class="sb-sidenav accordion sb-sidenav-dark" id="sidenavAccordion">
                <div class="sb-sidenav-menu">
                    <div class="nav">
                        <div class="sb-sidenav-menu-heading">Core</div>
                        <a class="nav-link" href="/">
                            <div class="sb-nav-link-icon"><i class="fas fa-tachometer-alt"></i></div>
                            Menu
                        </a>
                        <div class="sb-sidenav-menu-heading">Fonctions</div>
                        <a class="nav-link" href="docs.html">
                            <div class="sb-nav-link-icon"><i class="fas fa-columns"></i></div>
                            Docs
                        </a>
                        <a class="nav-link" href="codes.html">
                            <div class="sb-nav-link-icon"><i class="fas fa-book-open"></i></div>
                            Codes
                        </a>
                        <a class="nav-link" href="eval.html">
                            <div class="sb-nav-link-icon"><i class="fas fa-book-open"></i></div>
                            √âvaluation
                        </a>
                        <br>
                    </div>
                    <div class="sb-sidenav-footer">
                        <div class="small">Projet Web Interface</div>
                        <div class="small">By Xiaohua CUI, Yingzi LIU </div>
                    </div>
            </nav>
        </div>
        <div id="layoutSidenav_content">
            <main>
                <div class="container" style="margin-left: 40px;">
                    <div class="card-body">
                    </p>
                    <hr> <!-- Ligne de s√©paration -->
                    <!-- Nouveau contenu ajout√© -->
                    <p>
                        <h2>üìö Introduction</h2>
                        <p>
                            Dans le cadre de notre exploration approfondie de l'univers de la reconnaissance d'entit√©s
                            nomm√©es (NER), nous avons mis en ≈ìuvre une approche m√©thodique pour √©tudier et comparer
                            l'efficacit√© de divers mod√®les de renom dans ce domaine. Notre qu√™te nous a men√©s √†
                            s√©lectionner et √† utiliser trois mod√®les pr√©-entra√Æn√©s particuli√®rement distingu√©s, chacun
                            apportant une contribution unique √† notre compr√©hension globale de la NER. Voici les mod√®les
                            que nous avons choisis pour notre voyage :
                        </p>
                        <ul>
                            <li>
                                <strong>spaCy</strong> : Reconnu pour sa rapidit√© et son efficacit√©, le mod√®le
                                fr_core_news_sm de spaCy offre une base solide pour la reconnaissance d'entit√©s en
                                fran√ßais. C'est un choix privil√©gi√© pour les applications n√©cessitant une grande vitesse
                                de traitement et une bonne pr√©cision.
                            </li>
                            <li>
                                <strong>dslim/bert-base-NER</strong> : Ce mod√®le, bas√© sur l'architecture Transformer de
                                BERT et pr√©-entra√Æn√© sur un vaste corpus, est sp√©cialis√© dans la reconnaissance
                                d'entit√©s nomm√©es. Il est connu pour sa capacit√© √† comprendre le contexte des mots dans
                                des phrases, ce qui le rend extr√™mement efficace pour identifier avec pr√©cision divers
                                types d'entit√©s.
                            </li>
                            <li>
                                <strong>Babelscape/wikineural-multilingual-ner</strong> : Ce mod√®le tire parti de
                                l'apprentissage profond pour offrir une reconnaissance d'entit√©s nomm√©es dans plusieurs
                                langues, y compris le fran√ßais. Gr√¢ce √† son entra√Ænement sur des donn√©es provenant de
                                Wikipedia, il est capable de reconna√Ætre un large √©ventail d'entit√©s √† travers
                                diff√©rents domaines.
                            </li>
                            <li>
                                <strong>Fine-tuned TinyBERT</strong> : Au-del√† de l'adoption de mod√®les pr√©-entra√Æn√©s
                                r√©put√©s, nous avons √©galement pris l'initiative ambitieuse d'adapter un mod√®le pour
                                r√©pondre pr√©cis√©ment √† nos exigences particuli√®res. En tirant parti du <a
                                    href="https://huggingface.co/datasets/Babelscape/multinerd">MultiNERD dataset</a>,
                                nous avons proc√©d√© au fine-tuning d'un <a
                                    href="https://huggingface.co/huawei-noah/TinyBERT_General_4L_312D">mod√®le
                                    TinyBERT</a> sp√©cifiquement pour notre projet. Le choix de TinyBERT √©tait motiv√© par
                                sa structure l√©g√®re et efficace, rendant possible une haute performance tout en
                                maintenant une consommation de ressources r√©duite. TinyBERT se distingue dans le domaine
                                du TAL par sa capacit√© √† comprimer les mod√®les de langue de grande taille tout en
                                pr√©servant leur puissance et leur efficacit√©.
                            </li>
                        </ul>
                        <h2>üéØ Objectif</h2>
                        <p>
                            Notre mission principale est de cr√©er un portail web intergalactique qui permet aux
                            utilisateurs terriens de soumettre du texte en fran√ßais et d'obtenir des annotations de NER
                            d'une pr√©cision stellaire en utilisant quatre mod√®les distincts : le v√©n√©rable spaCy,
                            l'illustre BERT-base (dslim/bert-base-NER), l'√©nigmatique Wikineural
                            (Babelscape/wikineural-multilingual-ner) et l'intr√©pide TinyBERT, finetun√© avec le pr√©cieux
                            <a href="https://huggingface.co/datasets/Babelscape/multinerd">MultiNERD dataset</a>.
                            L'objectif est d'offrir aux utilisateurs un moyen direct et visuellement intuitif de
                            comparer les performances de chaque mod√®le, y compris notre adaptation personnalis√©e, pour
                            r√©pondre √† des besoins sp√©cifiques dans le domaine de la NER. Cette initiative entend
                            proposer une ressource transparente et facilement accessible, destin√©e √† faciliter la
                            recherche et l'exploitation pratique de la reconnaissance d'entit√©s nomm√©es (NER).
                        </p>
                        <h2>üë©‚ÄçüöÄüë®‚ÄçüöÄ Auteurs</h2>
                        <p>
                            Cette aventure cosmique a √©t√© entreprise par Yingzi LIU et Xiaohua CUI, deux courageux
                            √©tudiants de l'Universit√© Sorbonne Nouvelle, arm√©s de leur curiosit√© et de leur soif de
                            connaissance.
                        </p>
                        <h2>‚ú® Fonctionnalit√©s</h2>
                        <ul>
                            <li>Multi-mod√®les de Reconnaissance d'Entit√©s Nomm√©es (NER): Emploi de quatre puissants
                                mod√®les de NER pour classifier et annoter le texte soumis, r√©v√©lant les entit√©s telles
                                que les personnes, lieux, organisations, etc.</li>
                            <li>Interface Web: Nous proposons une interface web √©labor√©e et ergonomique, destin√©e aux
                                utilisateurs d√©sirant analyser des textes de mani√®re d√©taill√©e. Ce portail permet de
                                soumettre ais√©ment des √©crits ou documents pour une exploration NER compl√®te.</li>
                        </ul>
                        <h2>üì¶ Contenu du Projet</h2>
                        <ol>
                            <li>Mod√®les de NER: Une qu√™te √©pique √† travers diff√©rents mod√®les de NER, cherchant √†
                                d√©terminer le plus vaillant.</li>
                            <li>Fine-tuning de TinyBERT: L'art d√©licat d'adapter un mod√®le TinyBERT avec le tr√©sor cach√©
                                qu'est le MultiNERD dataset, dans le but d'am√©liorer sa performance sur des textes
                                sp√©cifiques.</li>
                            <li>D√©veloppement d'une Interface Web: La construction d'un portail interstellaire pour
                                soumettre des textes et visualiser les r√©sultats de NER, un v√©ritable pont entre l'homme
                                et la machine.</li>
                        </ol>
                        <h2>üöÄ Utilisation</h2>
                        <ol>
                            <li>Clonez le d√©p√¥t GitHub sur votre navire spatial (machine locale).</li>
                            <li>Installez les composants n√©cessaires avec `pip install -r requirements.txt`.</li>
                            <li>Lancez le serveur web avec `python app.py`.</li>
                            <li>Acc√©dez √† l'interface web via votre navigateur spatial pour soumettre du texte ou des
                                fichiers et recevoir des annotations de NER dignes d'une civilisation avanc√©e.</li>
                        </ol>
                    </p>
                    <hr> <!-- Ligne de s√©paration -->
                    <!-- Nouveau contenu ajout√© -->
                    <p>
                        <h2>üåü Fine-tuning TinyBERT üåü</h2>
                    </p>
                    <hr> <!-- Ligne de s√©paration -->
                    <!-- Nouveau contenu ajout√© -->
                    <p>
                        <h3>üîç Le Dataset MultiNERD</h3>
                        
                            <p> Pour cette √©tude, le dataset MultiNERD a √©t√© utilis√©. MultiNERD est une extension du c√©l√®bre dataset WikiANN pour la reconnaissance d'entit√©s nomm√©es multilingue. D√©velopp√© par Babelscape, il vise √† fournir une ressource riche et vari√©e pour l'entra√Ænement et l'√©valuation de mod√®les de REN dans plus de 40 langues, y compris le fran√ßais. Ce dataset contient des annotations pour une grande vari√©t√© de types d'entit√©s, offrant ainsi une base solide pour l'entra√Ænement de mod√®les de REN performants.
                        
                        <h3>üîß Fine-tuning de TinyBERT</h3>
                        
                            <p>TinyBERT est un mod√®le de langage transformateur con√ßu pour offrir une efficacit√© √©lev√©e et une performance remarquable dans diverses t√¢ches de traitement du langage naturel (TLP), tout en √©tant significativement plus petit et plus rapide que ses pr√©d√©cesseurs tels que BERT ou GPT. D√©velopp√© par Huawei Noah's Ark Lab, TinyBERT se distingue par sa structure compacte qui permet une utilisation optimale dans des environnements avec des ressources limit√©es, tels que des dispositifs mobiles ou des serveurs avec peu de capacit√© de calcul.</p>
                        <p>Les principaux avantages de TinyBERT r√©sident dans sa taille r√©duite et sa consommation √©nerg√©tique plus faible compar√©e √† des mod√®les plus grands, tout en maintenant des performances comp√©titives. Ces caract√©ristiques le rendent particuli√®rement adapt√© aux applications n√©cessitant des r√©ponses rapides et efficaces en termes de calcul, telles que la traduction en temps r√©el, l'assistance virtuelle, ou la reconnaissance d'entit√©s nomm√©es (REN) dans des documents textuels.</p>
                            <h3>üìê Application dans la Reconnaissance d'Entit√©s Nomm√©es</h3>
                           <p>La reconnaissance d'entit√©s nomm√©es est un domaine cl√© du TLP qui consiste √† identifier et classer des √©l√©ments sp√©cifiques dans un texte (tels que les noms de personnes, d'organisations, de lieux, etc.) dans des cat√©gories pr√©d√©termin√©es. L'application de TinyBERT √† cette t√¢che permet de b√©n√©ficier de sa rapidit√© d'ex√©cution et de son efficacit√©, m√™me sur des plateformes avec des capacit√©s de calcul limit√©es.</p>
                            <h3>üóúÔ∏è D√©fis Techniques</h3>
                           <p>L'entra√Ænement d'un mod√®le comme TinyBERT sur le dataset MultiNERD pr√©sente certains d√©fis, notamment en raison de contraintes de ressources telles que la m√©moire insuffisante et l'absence de GPU ou de CPU puissants. Ces limitations peuvent entra√Æner des interruptions et des √©checs lors de l'entra√Ænement du mod√®le.</p>
                    <h3>üß≤ Solutions Adopt√©es</h3>
                    <p>Pour surmonter ces obstacles, plusieurs ajustements ont √©t√© effectu√©s :</p>
                    <p>Augmentation du gradient_accumulation_steps : Cette approche permet d'accumuler les gradients sur plusieurs √©tapes avant de mettre √† jour les poids du mod√®le, r√©duisant ainsi le besoin en m√©moire et en puissance de calcul. Cela s'av√®re crucial dans des environnements avec des ressources limit√©es.</p>
                    <p>R√©duction des per_device_train_batch_size et per_device_eval_batch_size √† 1 : En diminuant la taille des lots pour l'entra√Ænement et l'√©valuation, on r√©duit la quantit√© de m√©moire n√©cessaire, permettant au mod√®le de s'ex√©cuter sur des appareils avec moins de ressources.</p>
                <p>S√©lection d'un sous-ensemble du dataset (subset_ratio = 0.1) : Face aux contraintes de ressources, r√©duire la taille du dataset d'entra√Ænement devient une n√©cessit√©. Bien que cette m√©thode puisse limiter la diversit√© et la quantit√© des donn√©es d'entra√Ænement, ce qui pourrait affecter la performance g√©n√©rale du mod√®le, elle permet n√©anmoins un entra√Ænement viable sans surcharger la m√©moire disponible.
                </p>
                <h3>üß≠ Conclusion</h3>
                <p>En conclusion, l'adaptation de TinyBERT pour la reconnaissance d'entit√©s nomm√©es en fran√ßais d√©montre la flexibilit√© et l'efficacit√© des mod√®les de langage transformateurs compacts dans des sc√©narios avec des ressources limit√©es. Malgr√© les d√©fis pos√©s par les limitations de l'environnement d'entra√Ænement, les ajustements apport√©s ont permis de mener √† bien l'entra√Ænement tout en maintenant une performance respectable. Ce travail souligne l'importance de l'optimisation des ressources dans le d√©veloppement d'applications de traitement du langage naturel, en particulier dans des contextes o√π l'acc√®s √† des ressources de calcul avanc√©es est limit√©.</p>
            </div>
                </div>
            </main>
        </div>

    </div>
    </div>
    </main>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"
        crossorigin="anonymous"></script>
    <script src="scripts.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.8.0/Chart.min.js" crossorigin="anonymous"></script>
    <script src="demo/chart-area-demo.js"></script>
    <script src="demo/chart-bar-demo.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/simple-datatables@7.1.2/dist/umd/simple-datatables.min.js"
        crossorigin="anonymous"></script>
    <script src="datatables-simple-demo.js"></script>

</body>

</html>